{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bae2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json  \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c67f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appel de l'API Reddit pour 'Sony XM5' dans r/headphones...\n",
      "\n",
      "--- ✅ SUCCÈS ! 10 posts trouvés : ---\n",
      "\n",
      "--- Post 1 (ID: 1odad1t) ---\n",
      "Titre: What are these?\n",
      "\n",
      "--- Post 2 (ID: 1occfmu) ---\n",
      "Titre: Audiophile Verdict of Bose QC Ultra 2 Headphones: DO NOT BUY 1ST GEN!\n",
      "\n",
      "--- Post 3 (ID: 1o1oqjf) ---\n",
      "Titre: Motion sickness from Sennheiser M4, should i switch to other brands?\n",
      "\n",
      "--- Post 4 (ID: 1nuylfe) ---\n",
      "Titre: Just bought Arya Stealth coming from Sony XM5 over ears. Will I notice a difference?\n",
      "\n",
      "--- Post 5 (ID: 1nf3m4a) ---\n",
      "Titre: Why do I struggle to enjoy over-ear headphones like the Sony XM4 or XM5, and how can I get used to them and start liking the experience?\n",
      "\n",
      "--- Post 6 (ID: 1n16nhe) ---\n",
      "Titre: How to disinfect/clean ear cups?\n",
      "\n",
      "--- Post 7 (ID: 1n13i3p) ---\n",
      "Titre: Bose QCU #FAIL Sony #FAIL are there any decent options left?\n",
      "\n",
      "--- Post 8 (ID: 1myfywb) ---\n",
      "Titre: Sonos Ace!\n",
      "\n",
      "--- Post 9 (ID: 1mjxnrh) ---\n",
      "Titre: Sony xm5 pros and cons\n",
      "\n",
      "--- Post 10 (ID: 1m27bsa) ---\n",
      "Titre: XM5\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "\n",
    "# --- 1. Configuration (les paramètres de ton pipeline) ---\n",
    "SUBREDDIT = \"headphones\"\n",
    "MOT_CLE = \"Sony XM5\" # Un mot-clé de ton fichier config\n",
    "\n",
    "# --- 2. Construction de l'URL et des Paramètres ---\n",
    "# On utilise l'endpoint de RECHERCHE de Reddit, au format JSON\n",
    "url = f\"https://www.reddit.com/r/{SUBREDDIT}/search.json\"\n",
    "\n",
    "# Paramètres de la recherche :\n",
    "params = {\n",
    "    'q': MOT_CLE,        # 'q' = query (le mot-clé que tu cherches)\n",
    "    'sort': 'new',       # 'new' = trier par \"plus récent\" (parfait pour ton pipeline)\n",
    "    'restrict_sr': 'true', # 'true' = restreindre la recherche à ce subreddit\n",
    "    'limit': 10          # On veut 10 résultats\n",
    "}\n",
    "\n",
    "# !! TRÈS IMPORTANT !!\n",
    "# Reddit bloque les scripts qui n'ont pas de \"User-Agent\".\n",
    "# On doit simuler un navigateur pour être poli et éviter un blocage.\n",
    "headers = {\n",
    "    'User-Agent': 'MonProjetDataEngineering-v0.1'\n",
    "}\n",
    "\n",
    "# --- 3. Exécution de l'Appel API ---\n",
    "print(f\"Appel de l'API Reddit pour '{MOT_CLE}' dans r/{SUBREDDIT}...\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    response.raise_for_status() # Vérifie s'il y a eu une erreur (ex: 404, 500)\n",
    "\n",
    "    # --- 4. Affichage du Résultat ---\n",
    "    data = response.json() # Convertit la réponse texte en objet JSON\n",
    "\n",
    "    # Les posts sont imbriqués dans cette structure\n",
    "    posts = data['data']['children']\n",
    "\n",
    "    if not posts:\n",
    "        print(f\"\\n Pas de nouveaux posts trouvés pour '{MOT_CLE}'. ---\")\n",
    "    else:\n",
    "        print(f\"\\n{len(posts)} posts trouvés : ---\")\n",
    "        \n",
    "        # --- 5. Début de la Transformation (ce que fera ton ETL) ---\n",
    "        for i, post in enumerate(posts):\n",
    "            post_data = post['data']\n",
    "            \n",
    "            titre = post_data['title']\n",
    "            texte_brut = post_data['selftext'] # Le corps du post\n",
    "            \n",
    "            print(f\"\\n--- Post {i+1} (ID: {post_data['id']}) ---\")\n",
    "            print(f\"Titre: {titre}\")\n",
    "            \n",
    "            \n",
    "            # Ton script d'analyse de sentiment lira ce titre et ce texte\n",
    "            # ... (Étape suivante: appliquer VADER ou TextBlob ici) ...\n",
    "\n",
    "\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print(f\"\\n--- ❌ ERREUR HTTP : {err} ---\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"\\n--- ❌ ERREUR de Connexion : {e} ---\")\n",
    "except KeyError:\n",
    "    print(\"\\n--- ❌ ERREUR de Parsing JSON ---\")\n",
    "    print(\"La structure de la réponse de Reddit a peut-être changé.\")\n",
    "    print(\"Réponse brute reçue :\", response.text[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ca8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appel de l'URL : https://www.fnac.com/Casque-Bluetooth-sans-fil/Casque-par-usage/nsh450503/w-4?SDM=list&ssi=6&sso=2...\n",
      "\n",
      "--- ❌ ERREUR HTTP : 403 Client Error: Forbidden for url: https://www.fnac.com/Casque-Bluetooth-sans-fil/Casque-par-usage/nsh450503/w-4?SDM=list&ssi=6&sso=2 ---\n",
      "   Cause probable : Blocage anti-scraping par le serveur.\n",
      "   Vérifie les 'headers'. Si ça persiste, une solution de proxy pourrait être nécessaire.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. Configuration ---\n",
    "URL_DECOUVERTE = \"https://www.fnac.com/Casque-Bluetooth-sans-fil/Casque-par-usage/nsh450503/w-4?SDM=list&ssi=6&sso=2\"\n",
    "\n",
    "# --- NOUVEAU : En-têtes plus complets ---\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7', # Préférer le français\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Referer': 'https://www.google.com/', # Simule une venue depuis Google\n",
    "    'DNT': '1', # Do Not Track\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1'\n",
    "}\n",
    "\n",
    "# --- 2. Scraping de la page ---\n",
    "print(f\"Appel de l'URL : {URL_DECOUVERTE}...\")\n",
    "try:\n",
    "    # Utilisation d'une session pour potentiellement gérer les cookies si nécessaire\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(URL_DECOUVERTE)\n",
    "    response.raise_for_status() # Lève une exception pour les codes 4xx/5xx\n",
    "\n",
    "    # ... (le reste de ton code pour parser avec BeautifulSoup reste le même) ...\n",
    "    # ... (trouver le div#FnacContent, extraire data-state, parser le JSON...) ...\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    main_div = soup.find('div', id='FnacContent')\n",
    "    \n",
    "    if not main_div or 'data-state' not in main_div.attrs:\n",
    "        print(\"\\n--- ❌ ERREUR : Impossible de trouver le JSON 'data-state'. ---\")\n",
    "    else:\n",
    "        json_string = main_div['data-state']\n",
    "        data = json.loads(json_string)\n",
    "        references = data.get('references', [])\n",
    "        \n",
    "        if not references:\n",
    "            print(\"\\n--- ⚠️ Pas de produits trouvés dans le JSON 'references'. ---\")\n",
    "        else:\n",
    "            print(f\"\\n--- ✅ SUCCÈS : {len(references)} produits découverts via JSON ---\")\n",
    "            liste_produits = []\n",
    "            for ref in references:\n",
    "                prid = ref.get('prid')\n",
    "                if prid:\n",
    "                    # !! VÉRIFIE CE FORMAT D'URL !!\n",
    "                    product_url = f\"https://www.fnac.com/a{prid}/w-4\" \n",
    "                    liste_produits.append({\"prid\": prid, \"url\": product_url})\n",
    "\n",
    "            print(\"\\n--- Liste des produits découverts (PRID et URL) : ---\")\n",
    "            for p in liste_produits[:5]: \n",
    "                 print(p)\n",
    "\n",
    "\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    # Affichage plus détaillé de l'erreur 403\n",
    "    print(f\"\\n--- ❌ ERREUR HTTP : {err} ---\") \n",
    "    if response.status_code == 403:\n",
    "        print(\"   Cause probable : Blocage anti-scraping par le serveur.\")\n",
    "        print(\"   Vérifie les 'headers'. Si ça persiste, une solution de proxy pourrait être nécessaire.\")\n",
    "    else:\n",
    "        print(\"   Le serveur a retourné une erreur.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"\\n--- ❌ ERREUR : Impossible de parser le JSON dans 'data-state'. ---\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ❌ ERREUR INATTENDUE : {e} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a9124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentative d'accès à : https://www.vandenborre.be/fr/mp3-casque-ecouteurs/casque...\n",
      "\n",
      "--- ✅ SUCCÈS ! Code statut : 200 ---\n",
      "Le site semble accessible au scraping basique.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "URL_TEST = \"https://www.vandenborre.be/fr/mp3-casque-ecouteurs/casque\"\n",
    "\n",
    "# En-têtes pour simuler un navigateur\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Referer': 'https://www.google.com/',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1'\n",
    "}\n",
    "\n",
    "# --- 2. Exécution du Test ---\n",
    "print(f\"Tentative d'accès à : {URL_TEST}...\")\n",
    "try:\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(URL_TEST, timeout=10) # Ajout d'un timeout\n",
    "    response.raise_for_status() # Lève une exception pour les codes 4xx/5xx\n",
    "\n",
    "    # --- 3. Résultat ---\n",
    "    print(f\"\\n--- ✅ SUCCÈS ! Code statut : {response.status_code} ---\")\n",
    "    print(\"Le site semble accessible au scraping basique.\")\n",
    "    # On pourrait ajouter ici une vérification rapide du contenu pour être sûr\n",
    "    # print(f\"Contenu reçu (premiers 200 chars): {response.text[:200]}...\")\n",
    "\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print(f\"\\n--- ❌ ERREUR HTTP : {err} ---\")\n",
    "    if response.status_code == 403:\n",
    "        print(\"   Cause probable : Blocage anti-scraping (similaire à FNAC).\")\n",
    "    else:\n",
    "        print(f\"   Le serveur a retourné une erreur {response.status_code}.\")\n",
    "except requests.exceptions.Timeout:\n",
    "     print(\"\\n--- ❌ ERREUR : La requête a expiré (Timeout). Le serveur est peut-être lent ou bloque.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"\\n--- ❌ ERREUR de Connexion : {e} ---\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ❌ ERREUR INATTENDUE : {e} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cccacdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping : https://www.vandenborre.be/fr/mp3-casque-ecouteurs/casque...\n",
      "\n",
      "--- ✅ 29 conteneurs produits trouvés ---\n",
      "\n",
      "--- Données extraites (5 premiers produits) : ---\n",
      "[\n",
      "  {\n",
      "    \"product_id\": \"7819145\",\n",
      "    \"name\": \"JBL TUNE 770NC BLACK\",\n",
      "    \"url\": \"https://www.vandenborre.be/fr/casque/jbl-tune-770nc-black\",\n",
      "    \"price\": 89.0,\n",
      "    \"rating\": 4.4,\n",
      "    \"review_count\": 70,\n",
      "    \"brand\": \"JBL\"\n",
      "  },\n",
      "  {\n",
      "    \"product_id\": \"7683081\",\n",
      "    \"name\": \"SONY WH-1000XM6 NOIR\",\n",
      "    \"url\": \"https://www.vandenborre.be/fr/casque/sony-wh-1000xm6-noir\",\n",
      "    \"price\": 449.0,\n",
      "    \"rating\": 4.8,\n",
      "    \"review_count\": 17,\n",
      "    \"brand\": \"SONY\"\n",
      "  },\n",
      "  {\n",
      "    \"product_id\": \"7762429\",\n",
      "    \"name\": \"JBL LIVE 770NC NOIR\",\n",
      "    \"url\": \"https://www.vandenborre.be/fr/casque/jbl-live-770nc-noir\",\n",
      "    \"price\": 120.0,\n",
      "    \"rating\": 4.5,\n",
      "    \"review_count\": 147,\n",
      "    \"brand\": \"JBL\"\n",
      "  },\n",
      "  {\n",
      "    \"product_id\": \"7825773\",\n",
      "    \"name\": \"JBL TUNE 520 BT BLACK\",\n",
      "    \"url\": \"https://www.vandenborre.be/fr/casque/jbl-tune-520-bt-black\",\n",
      "    \"price\": 46.99,\n",
      "    \"rating\": 4.0,\n",
      "    \"review_count\": 61,\n",
      "    \"brand\": \"JBL\"\n",
      "  },\n",
      "  {\n",
      "    \"product_id\": \"7820852\",\n",
      "    \"name\": \"JBL TUNE 670NC BLACK\",\n",
      "    \"url\": \"https://www.vandenborre.be/fr/casque/jbl-tune-670nc-black\",\n",
      "    \"price\": 63.99,\n",
      "    \"rating\": 4.5,\n",
      "    \"review_count\": 119,\n",
      "    \"brand\": \"JBL\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "URL_DECOUVERTE = \"https://www.vandenborre.be/fr/mp3-casque-ecouteurs/casque\"\n",
    "BASE_URL = \"https://www.vandenborre.be\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Referer': 'https://www.google.com/',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1'\n",
    "}\n",
    "\n",
    "print(f\"Scraping : {URL_DECOUVERTE}...\")\n",
    "try:\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(URL_DECOUVERTE, timeout=15)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    product_containers = soup.find_all('div', {'class': 'js-product-container'})\n",
    "\n",
    "    if not product_containers:\n",
    "        print(\"\\n--- ⚠️ Aucun conteneur produit trouvé avec 'div.js-product-container'. Vérifie les sélecteurs. ---\")\n",
    "\n",
    "    print(f\"\\n--- ✅ {len(product_containers)} conteneurs produits trouvés ---\")\n",
    "\n",
    "    produits_decouverts = []\n",
    "\n",
    "    for container in product_containers:\n",
    "        product_id = container.get('data-productid')\n",
    "        if not product_id:\n",
    "            continue\n",
    "\n",
    "        product_data = {\"product_id\": product_id}\n",
    "\n",
    "        # URL et Nom\n",
    "        name_tag = container.find('h2', {'class': 'productname'})\n",
    "        link_tag = container.find('a', {'class': 'js-product-click'})\n",
    "        if name_tag and link_tag and link_tag.get('href'):\n",
    "            product_data[\"name\"] = name_tag.text.strip()\n",
    "            # Construit l'URL complète\n",
    "            relative_url = link_tag['href']\n",
    "            if relative_url.startswith('//'):\n",
    "                product_data[\"url\"] = f\"https:{relative_url}\"\n",
    "            elif relative_url.startswith('/'):\n",
    "                 product_data[\"url\"] = f\"{BASE_URL}{relative_url}\"\n",
    "            else:\n",
    "                 product_data[\"url\"] = relative_url # Au cas où elle serait déjà complète\n",
    "        else:\n",
    "            product_data[\"name\"] = \"Nom non trouvé\"\n",
    "            product_data[\"url\"] = \"URL non trouvée\"\n",
    "\n",
    "        # Prix\n",
    "        price_tag = container.find('span', {'class': 'current'})\n",
    "        if price_tag:\n",
    "            price_text = price_tag.text.strip().replace('€', '').replace(',', '.').replace('\\xa0', '').replace(' ', '')\n",
    "            try:\n",
    "                product_data[\"price\"] = float(re.sub(r'[^\\d\\.]', '', price_text))\n",
    "            except (ValueError, TypeError):\n",
    "                 product_data[\"price\"] = None\n",
    "        else:\n",
    "            product_data[\"price\"] = None\n",
    "\n",
    "        # Note et Avis\n",
    "        rating_score_tag = container.find('div', {'class': 'rating-score'})\n",
    "        review_count_tag = container.find('div', {'class': 'rating-reviews-amount'})\n",
    "\n",
    "        if rating_score_tag and rating_score_tag.find('strong'):\n",
    "            rating_text = rating_score_tag.find('strong').text.strip().replace(',', '.')\n",
    "            try:\n",
    "                product_data[\"rating\"] = float(rating_text)\n",
    "            except (ValueError, TypeError):\n",
    "                 product_data[\"rating\"] = None\n",
    "        else:\n",
    "             product_data[\"rating\"] = None\n",
    "\n",
    "        if review_count_tag and review_count_tag.find('a'):\n",
    "            review_text = review_count_tag.find('a').text.strip()\n",
    "            count_match = re.search(r'\\((\\d+)\\)', review_text)\n",
    "            if count_match:\n",
    "                 try:\n",
    "                    product_data[\"review_count\"] = int(count_match.group(1))\n",
    "                 except (ValueError, TypeError):\n",
    "                    product_data[\"review_count\"] = None\n",
    "            else:\n",
    "                 product_data[\"review_count\"] = None\n",
    "        else:\n",
    "            product_data[\"review_count\"] = None\n",
    "            \n",
    "        # Marque (simple extraction du premier mot du nom)\n",
    "        if product_data[\"name\"] != \"Nom non trouvé\":\n",
    "             product_data[\"brand\"] = product_data[\"name\"].split(' ')[0]\n",
    "        else:\n",
    "             product_data[\"brand\"] = None\n",
    "\n",
    "\n",
    "        produits_decouverts.append(product_data)\n",
    "\n",
    "    print(\"\\n--- Données extraites (5 premiers produits) : ---\")\n",
    "    if produits_decouverts:\n",
    "        print(json.dumps(produits_decouverts[:5], indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"Aucun produit n'a pu être extrait.\")\n",
    "\n",
    "\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print(f\"\\n--- ❌ ERREUR HTTP : {err} ---\")\n",
    "    if response and response.status_code == 403:\n",
    "        print(\"   Cause : Blocage anti-scraping.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ❌ ERREUR INATTENDUE : {e} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f242c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de mentions dans r/headphones...\n",
      "\n",
      "--- Recherche de 'JBL Tune 770NC' ---\n",
      "   -> ✅ Trouvé 5 mentions récentes pour 'JBL Tune 770NC'.\n",
      "      Exemple: 'I have no idea which headphone to go ahead with after this one broke...'\n",
      "--- Recherche de 'Sony WH-1000XM6' ---\n",
      "   -> ✅ Trouvé 5 mentions récentes pour 'Sony WH-1000XM6'.\n",
      "      Exemple: 'first impression on sony’s WH-1000XM6, i have one complaint...'\n",
      "--- Recherche de 'JBL Live 770NC' ---\n",
      "   -> ✅ Trouvé 5 mentions récentes pour 'JBL Live 770NC'.\n",
      "      Exemple: 'I saw someone wearing the xm4’s...'\n",
      "\n",
      "--- Résultat du Test ---\n",
      "✅ Confirmation : Au moins 3/3 produits testés ont des mentions récentes sur Reddit.\n",
      "   -> La Source 3 (Sentiment) semble viable.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "SUBREDDIT = \"headphones\"\n",
    "# Liste des mots-clés correspondant aux produits trouvés\n",
    "PRODUITS_A_TESTER = [\n",
    "    \"JBL Tune 770NC\", \n",
    "    \"Sony WH-1000XM6\", \n",
    "    \"JBL Live 770NC\" \n",
    "]\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'MonProjetDataEngineering-TestMention-v0.1' \n",
    "}\n",
    "\n",
    "# --- 2. Boucle de Test ---\n",
    "print(f\"Test de mentions dans r/{SUBREDDIT}...\\n\")\n",
    "produits_avec_mentions = 0\n",
    "\n",
    "for mot_cle in PRODUITS_A_TESTER:\n",
    "    print(f\"--- Recherche de '{mot_cle}' ---\")\n",
    "    \n",
    "    url = f\"https://www.reddit.com/r/{SUBREDDIT}/search.json\"\n",
    "    params = {\n",
    "        'q': mot_cle,\n",
    "        'sort': 'new',\n",
    "        'restrict_sr': 'true',\n",
    "        'limit': 5 # On ne cherche que 5 posts pour ce test\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        posts = data['data']['children']\n",
    "\n",
    "        if not posts:\n",
    "            print(f\"   -> ⚠️ Aucune mention récente trouvée pour '{mot_cle}'.\")\n",
    "        else:\n",
    "            print(f\"   -> ✅ Trouvé {len(posts)} mentions récentes pour '{mot_cle}'.\")\n",
    "            # Afficher le titre du premier post trouvé pour vérification\n",
    "            print(f\"      Exemple: '{posts[0]['data']['title'][:80]}...'\")\n",
    "            produits_avec_mentions += 1\n",
    "            \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"   -> ❌ ERREUR HTTP lors de la recherche de '{mot_cle}': {err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   -> ❌ ERREUR INATTENDUE lors de la recherche de '{mot_cle}': {e}\")\n",
    "        \n",
    "    # Pause de politesse pour respecter les limites de Reddit\n",
    "    time.sleep(1) \n",
    "\n",
    "# --- 3. Conclusion du Test ---\n",
    "print(\"\\n--- Résultat du Test ---\")\n",
    "if produits_avec_mentions > 0:\n",
    "    print(f\"✅ Confirmation : Au moins {produits_avec_mentions}/{len(PRODUITS_A_TESTER)} produits testés ont des mentions récentes sur Reddit.\")\n",
    "    print(\"   -> La Source 3 (Sentiment) semble viable.\")\n",
    "else:\n",
    "     print(\"❌ Problème : Aucun des produits testés n'a de mention récente sur Reddit.\")\n",
    "     print(\"   -> La Source 3 (Sentiment Reddit) pourrait être difficile à alimenter pour ce marché.\")\n",
    "     print(\"   -> Envisage d'élargir les mots-clés ou de changer de subreddit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f14b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping (JSON Caché) : https://www.vandenborre.be/fr/casque/jbl-tune-770nc-black...\n",
      "\n",
      "--- ✅ SUCCÈS ! Données JSON 'Product' extraites : ---\n",
      "\n",
      "--- Pour Dim_Product (Catalogue) ---\n",
      "SKU: 7819145\n",
      "Nom: JBL TUNE 770NC BLACK\n",
      "Marque: JBL\n",
      "Catégorie: Casque audio\n",
      "\n",
      "--- Pour Fact_Marketplace_Snapshot (Performances) ---\n",
      "Prix: 89\n",
      "Note: 4.4\n",
      "Nb Avis: 70\n",
      "Dispo: https://schema.org/InStock\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "\n",
    "URL_PRODUIT = \"https://www.vandenborre.be/fr/casque/jbl-tune-770nc-black\"\n",
    "BASE_URL = \"https://www.vandenborre.be\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "}\n",
    "\n",
    "print(f\"Scraping (JSON Caché) : {URL_PRODUIT}...\")\n",
    "try:\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(URL_PRODUIT, timeout=15)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # --- 3. Extraction du JSON (Version corrigée) ---\n",
    "    \n",
    "    # Trouve TOUS les scripts JSON-LD\n",
    "    json_scripts = soup.find_all('script', {'type': 'application/ld+json'})\n",
    "    \n",
    "    product_data = None # Variable pour stocker le bon JSON\n",
    "\n",
    "    for script in json_scripts:\n",
    "        if not script.string:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            data = json.loads(script.string)\n",
    "            \n",
    "            # Cas 1: Le JSON est un dictionnaire\n",
    "            if isinstance(data, dict) and data.get(\"@type\") == \"Product\":\n",
    "                product_data = data\n",
    "                break # On a trouvé le bon JSON, on arrête la boucle\n",
    "                \n",
    "            # Cas 2: Le JSON est une liste de dictionnaires\n",
    "            if isinstance(data, list):\n",
    "                for item in data:\n",
    "                    if isinstance(item, dict) and item.get(\"@type\") == \"Product\":\n",
    "                        product_data = item\n",
    "                        break # On a trouvé le bon JSON\n",
    "            if product_data:\n",
    "                break\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            continue # Ignorer les scripts JSON mal formés\n",
    "\n",
    "    # --- 4. Affichage du Résultat ---\n",
    "    if not product_data:\n",
    "        print(\"\\n--- ❌ ERREUR : Impossible de trouver le JSON '@type': 'Product' dans la page. ---\")\n",
    "    else:\n",
    "        print(\"\\n--- ✅ SUCCÈS ! Données JSON 'Product' extraites : ---\")\n",
    "        \n",
    "        # Données pour Dim_Product\n",
    "        print(\"\\n--- Pour Dim_Product (Catalogue) ---\")\n",
    "        print(f\"SKU: {product_data.get('sku')}\")\n",
    "        print(f\"Nom: {product_data.get('name')}\")\n",
    "        print(f\"Marque: {product_data.get('brand', {}).get('name')}\")\n",
    "        print(f\"Catégorie: {product_data.get('category')}\")\n",
    "        \n",
    "        # Données pour Fact_Marketplace_Snapshot\n",
    "        print(\"\\n--- Pour Fact_Marketplace_Snapshot (Performances) ---\")\n",
    "        print(f\"Prix: {product_data.get('offers', {}).get('price')}\")\n",
    "        print(f\"Note: {product_data.get('aggregateRating', {}).get('ratingValue')}\")\n",
    "        print(f\"Nb Avis: {product_data.get('aggregateRating', {}).get('reviewCount')}\")\n",
    "        print(f\"Dispo: {product_data.get('offers', {}).get('availability')}\")\n",
    "\n",
    "\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print(f\"\\n--- ❌ ERREUR HTTP : {err} ---\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ❌ ERREUR INATTENDUE : {e} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5112faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DB_CONFIG = {\n",
    "    'server': 'LAPTOP-VT8FTHG2\\DATAENGINEER', # ex: '.\\SQLEXPRESS' ou 'MON-PC\\NOM_INSTANCE'\n",
    "    'database': 'Projet_Market_Staging',\n",
    "    'driver': '{ODBC Driver 17 for SQL Server}',\n",
    "    'connection_string': (\n",
    "        \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "        \"SERVER=LAPTOP-VT8FTHG2\\DATAENGINEER;\" # Doit être le même que 'server'\n",
    "        \"DATABASE=Projet_Market_Staging;\"\n",
    "        \"Trusted_Connection=yes;\" # La ligne clé pour l'authentification Windows\n",
    "    )\n",
    "}\n",
    "\n",
    "# --- 2. Configuration du Scraper ---\n",
    "URL_DECOUVERTE = \"https://www.vandenborre.be/fr/mp3-casque-ecouteurs/casque\" \n",
    "BASE_URL = \"https://www.vandenborre.be\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "}\n",
    "\n",
    "\n",
    "try:\n",
    "    # Etape E (Extraction)\n",
    "    print(f\"Scraping : {URL_DECOUVERTE}...\")\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(URL_DECOUVERTE, timeout=15)\n",
    "    response.raise_for_status()\n",
    "    print(\"   -> ✅ Page 'Découverte' scrapée avec succès.\")\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Etape T (Transformation)\n",
    "    product_containers = soup.find_all('div', {'class': 'js-product-container'})\n",
    "    \n",
    "    if not product_containers:\n",
    "        print(\"--- Fin : Aucun conteneur produit trouvé. ---\")\n",
    "        exit()\n",
    "        \n",
    "    print(f\"   -> ✅ {len(product_containers)} produits trouvés sur la page.\")\n",
    "\n",
    "    # Etape L (Load)\n",
    "    print(\"Connexion à la base de données Staging (Auth Windows)...\")\n",
    "    \n",
    "    # Correction de la chaîne de connexion pour l'adapter à tes infos\n",
    "    conn_str = DB_CONFIG['connection_string'].replace('NOM_DE_TON_SERVEUR_SQL', DB_CONFIG['server'])\n",
    "                                                \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"   -> ✅ Connecté à SQL Server.\")\n",
    "\n",
    "    insert_count = 0\n",
    "    for container in product_containers:\n",
    "        sku = container.get('data-productid')\n",
    "        if not sku:\n",
    "            continue\n",
    "\n",
    "        link_tag = container.find('a', {'class': 'js-product-click'})\n",
    "        if not link_tag or not link_tag.get('href'):\n",
    "            continue\n",
    "            \n",
    "        # Reconstruction de l'URL\n",
    "        relative_url = link_tag['href']\n",
    "        if relative_url.startswith('//'):\n",
    "            product_url = f\"https:{relative_url}\"\n",
    "        else:\n",
    "            product_url = f\"{BASE_URL}{relative_url}\"\n",
    "\n",
    "        # On vérifie si ce produit est déjà en attente de scraping\n",
    "        cursor.execute(\"SELECT 1 FROM Staging_Scraping_Queue WHERE ProductID_SKU = ? AND Status = 'pending'\", (sku))\n",
    "        if cursor.fetchone() is None:\n",
    "            # Nouveau produit à scraper : on l'ajoute à la file d'attente\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO Staging_Scraping_Queue (ProductID_SKU, ProductURL, Status, DiscoveredAt) VALUES (?, ?, 'pending', GETDATE())\",\n",
    "                (sku, product_url)\n",
    "            )\n",
    "            insert_count += 1\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"   -> ✅ {insert_count} nouveaux produits insérés dans Staging_Scraping_Queue.\")\n",
    "    \n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print(f\"\\n--- ❌ ERREUR HTTP : {err} ---\")\n",
    "except pyodbc.Error as ex:\n",
    "    sqlstate = ex.args[0]\n",
    "    print(f\"\\n--- ❌ ERREUR SQL Server : {sqlstate} ---\")\n",
    "    print(\"Vérifie tes 'DB_CONFIG': nom du serveur, nom de la base, et que le driver ODBC est installé.\")\n",
    "    print(f\"Chaîne de connexion tentée : {conn_str}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- ❌ ERREUR INATTENDUE : {e} ---\")\n",
    "finally:\n",
    "    if 'cursor' in locals() and cursor:\n",
    "        cursor.close()\n",
    "    if 'conn' in locals() and conn:\n",
    "        conn.close()\n",
    "        print(\"Connexion SQL Server fermée.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
